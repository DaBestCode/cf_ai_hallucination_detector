name = "cf-ai-hallucination-detector"
main = "worker/dist/index.js"
compatibility_date = "2024-07-28"
workers_dev = true # Allows local testing

type = "module"

[vars]
# Optional: Set a flag for the LLM model name
LLM_MODEL = "@cf/meta/llama-3.1-8b-instruct" # Or use @cf/meta/llama-3-8b-instruct if 3.1 is unavailable

[[migrations]]
tag = "v1" # Use a descriptive tag
new_sqlite_classes = [ "DurableChat" ]

# 1. AI Binding
[ai]
binding = "AI" # This makes the AI available as env.AI in the Worker

# 2. Durable Object Binding for Memory/State
[durable_objects]
bindings = [
  { name = "CHAT_STATE", class_name = "DurableChat" } # Accessible as env.CHAT_STATE
]

# 3. Worker Configuration (default environment)
[build]
command = "npm run build --workspace worker"


# 4. Pages Configuration (Optional, for easy deployment of the static frontend)
# Note: You'd typically deploy Pages separately, but this placeholder is good.
# [pages]
# route = "/*" # Catch all routes if deploying the frontend via the Worker